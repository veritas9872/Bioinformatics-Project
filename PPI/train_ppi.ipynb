{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/veritas/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from absl import flags\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from PPI.utils import load_edgelist_data, sparse_to_info, process_graph, split_graph_edges\n",
    "from model.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set hyper-parameters.\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float(name='lr', default=0.001, help='learning rate', lower_bound=0.)\n",
    "flags.DEFINE_float(name='val_r', default=0.02, help='Validation set ratio', lower_bound=0., upper_bound=1.)\n",
    "flags.DEFINE_float(name='test_r', default=0.02, help='Test set ratio', lower_bound=0., upper_bound=1.)\n",
    "flags.DEFINE_integer(name='seed', default=None, help='Seed for data split. Not the seed for model training.')\n",
    "flags.DEFINE_float(name='dropout', default=0., help='Dropout rate.', lower_bound=0, upper_bound=1)\n",
    "flags.DEFINE_bool(name='bias', default=True, help='Whether to use bias in GCN model.')\n",
    "flags.DEFINE_integer(name='num_hidden', default=32, \n",
    "                     help='Number of hidden features for the GCN model, which has only 1 hidden layer.', lower_bound=1)\n",
    "flags.DEFINE_integer(name='epochs', default=20, help='Number of training epochs.', lower_bound=1)\n",
    "flags.DEFINE_string(name='logs', default='./logs', \n",
    "                    help='root directory for logs, checkpoints, and other records.')\n",
    "FLAGS.mark_as_parsed()  # This is necessary for using FLAGS in jupyter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = '../data/yeast.edgelist'\n",
    "adj = load_edgelist_data(data_path)  # Get adjacency matrix in CSR format.\n",
    "\n",
    "# The adjacency matrix is symmetric but has non-zero elements on the diagonal.\n",
    "num_nodes = adj.shape[0]\n",
    "num_edges = adj.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "adj_orig = adj - sp.diags(adj.diagonal())\n",
    "adj_orig.eliminate_zeros()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "adj_train, edges_train, edges_val, edges_val_fake, edges_test, edges_test_fake = \\\n",
    "    split_graph_edges(adj, val_ratio=FLAGS.val_r, test_ratio=FLAGS.test_r, seed=FLAGS.seed)\n",
    "\n",
    "norm_edges, norm_data, norm_shape = process_graph(adj_train)\n",
    "adj_train_norm = tf.SparseTensor(indices=norm_edges, values=norm_data, dense_shape=norm_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = GCN(num_features=num_nodes, num_hidden=FLAGS.num_hidden, \n",
    "            num_classes=num_nodes, dropout=FLAGS.dropout, bias=FLAGS.bias)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=FLAGS.lr)\n",
    "log_dir = Path(FLAGS.logs)\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "log_dir /= f'log_{len(list(log_dir.iterdir())) + 1}'\n",
    "writer = tf.summary.create_file_writer(logdir=str(log_dir))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "lab_edges, lab_data, lab_shape = sparse_to_info(adj_train + sp.identity(num_nodes, dtype=np.float32))\n",
    "adj_labels = tf.sparse.to_dense(tf.SparseTensor(indices=lab_edges, values=lab_data, dense_shape=lab_shape))\n",
    "\n",
    "oh_edges, oh_data, oh_shape =sparse_to_info(sp.identity(num_nodes, dtype=np.float32))\n",
    "one_hot = tf.SparseTensor(indices=oh_edges, values=oh_data, dense_shape=oh_shape)\n",
    "position_weight = (num_nodes ** 2 - num_edges) / num_edges\n",
    "norm = num_nodes ** 2 / (2 * (num_nodes ** 2 - num_edges))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with writer.as_default():\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(1, FLAGS.epochs+1)):  # Only 1 training iteration per epoch.\n",
    "        tic = time()\n",
    "        inputs = [one_hot, adj_train_norm]\n",
    "        \n",
    "        with tf.GradientTape() as tape:  # Begin gradient calculations from here.\n",
    "            outputs = model(inputs, training=True)        \n",
    "            loss = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n",
    "                labels=adj_labels, logits=outputs, pos_weight=position_weight))\n",
    "        variables = model.trainable_variables\n",
    "        gradients = tape.gradient(target=loss, sources=variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(gradients, variables))\n",
    "        \n",
    "        toc = int(time() - tic)\n",
    "        print(f'Epoch {epoch:03d} Time: {toc}s, loss: {float(loss):.3f}')\n",
    "        tf.summary.scalar(name='Training Loss', data=loss, step=epoch, description='Training loss for each epoch.')\n",
    "    else:\n",
    "        writer.flush()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
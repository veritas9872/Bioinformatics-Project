{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/veritas/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from absl import flags\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from PPI.utils import load_edgelist_data, sparse_to_info, process_graph, split_graph_edges\n",
    "from model.gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set hyper-parameters.\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float(name='lr', default=0.001, help='learning rate', lower_bound=0.)\n",
    "flags.DEFINE_float(name='val_r', default=0.02, help='Validation set ratio', lower_bound=0., upper_bound=1.)\n",
    "flags.DEFINE_float(name='test_r', default=0.02, help='Test set ratio', lower_bound=0., upper_bound=1.)\n",
    "flags.DEFINE_integer(name='seed', default=None, help='Seed for data split. Not the seed for model training.')\n",
    "flags.DEFINE_integer(name='epochs', default=20, help='Number of training epochs.', lower_bound=1)\n",
    "flags.DEFINE_string(name='logs', default='./logs', \n",
    "                    help='root directory for logs, checkpoints, and other records.')\n",
    "FLAGS.mark_as_parsed()  # This is necessary for using FLAGS in jupyter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_path = '../data/yeast.edgelist'\n",
    "adj = load_edgelist_data(data_path)  # Get adjacency matrix in CSR format.\n",
    "\n",
    "# The adjacency matrix is symmetric but has non-zero elements on the diagonal.\n",
    "num_nodes = adj.shape[0]\n",
    "num_edges = adj.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "adj_orig = adj - sp.diags(adj.diagonal())\n",
    "adj_orig.eliminate_zeros()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "adj_train, edges_train, edges_val, edges_val_fake, edges_test, edges_test_fake = \\\n",
    "    split_graph_edges(adj, val_ratio=FLAGS.val_r, test_ratio=FLAGS.test_r, seed=FLAGS.seed)\n",
    "\n",
    "norm_edges, norm_data, norm_shape = process_graph(adj_train)\n",
    "adj_train_norm = tf.SparseTensor(indices=norm_edges, values=norm_data, dense_shape=norm_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-930444f69de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nonzero_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \"\"\"\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1258\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ],
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error"
    }
   ],
   "source": [
    "model = GCN(num_features=num_nodes, num_nonzero_features=num_nodes, h1=num_nodes, h2=num_nodes, dropout=0)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=FLAGS.lr)\n",
    "log_dir = Path(FLAGS.logs)\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "log_dir /= f'log_{len(list(log_dir.iterdir())) + 1}'\n",
    "writer = tf.summary.create_file_writer(logdir=str(log_dir))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lab_edges, lab_data, lab_shape = sparse_to_info(adj_train + sp.identity(num_nodes, dtype=np.float32))\n",
    "adj_labels = tf.sparse.to_dense(tf.SparseTensor(indices=lab_edges, values=lab_data, dense_shape=lab_shape))\n",
    "\n",
    "oh_edges, oh_data, oh_shape =sparse_to_info(sp.identity(num_nodes, dtype=np.float32))\n",
    "one_hot = tf.SparseTensor(indices=oh_edges, values=oh_data, dense_shape=oh_shape)\n",
    "position_weight = (num_nodes ** 2 - num_edges) / num_edges\n",
    "norm = num_nodes ** 2 / (2 * (num_nodes ** 2 - num_edges))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with writer.as_default():\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(1, FLAGS.epochs+1)):  # Only 1 training iteration per epoch.\n",
    "        tic = time()\n",
    "        inputs = [one_hot, adj_train_norm]\n",
    "        \n",
    "        with tf.GradientTape() as tape:  # Begin gradient calculations from here.\n",
    "            outputs = model(inputs, training=True)        \n",
    "            loss = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n",
    "                labels=adj_labels, logits=outputs, pos_weight=position_weight))\n",
    "        variables = model.trainable_variables\n",
    "        gradients = tape.gradient(target=loss, sources=variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(gradients, variables))\n",
    "        \n",
    "        toc = int(time() - tic)\n",
    "        print(f'Epoch {epoch:03d} Time: {toc}s, loss: {float(loss):.3f}')\n",
    "        tf.summary.scalar(name='Training Loss', data=loss, step=epoch, description='Training loss for each epoch.')\n",
    "    else:\n",
    "        writer.flush()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
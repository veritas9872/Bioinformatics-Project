{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bis438 Final Project Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baseline/.conda/envs/test/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "\n",
    "from model import GCN, MLP\n",
    "from utils import process_prediction, make_feature, split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "## Build GraphConv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "gcn_model = GCN(batch_size=batch_size) # build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GraphConv Model and Calculate ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ../data/bace.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 3.220 s\n",
      "TIMING: dataset construction took 3.879 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.851 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.588 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.405 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.228 s\n",
      "Loading dataset from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baseline/.conda/envs/test/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.7551765140304612]\n",
      "computed_metrics: [0.7313538352774832]\n",
      "computed_metrics: [0.7265475984047165]\n",
      "Evaluating model number  0\n",
      "Train ROC-AUC Score:  0.7551765140304612 Valid ROC-AUC Score:  0.7313538352774832 Test ROC-AUC Score:  0.7265475984047165\n",
      "TIMING: dataset construction took 0.795 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.235 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.232 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8228046022494634]\n",
      "computed_metrics: [0.8720112517580871]\n",
      "computed_metrics: [0.8034420289855073]\n",
      "Evaluating model number  1\n",
      "Train ROC-AUC Score:  0.8228046022494634 Valid ROC-AUC Score:  0.8720112517580871 Test ROC-AUC Score:  0.8034420289855073\n",
      "TIMING: dataset construction took 0.802 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.239 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.234 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8600624076565153]\n",
      "computed_metrics: [0.8529929577464789]\n",
      "computed_metrics: [0.7661458333333333]\n",
      "Evaluating model number  2\n",
      "Train ROC-AUC Score:  0.8600624076565153 Valid ROC-AUC Score:  0.8529929577464789 Test ROC-AUC Score:  0.7661458333333333\n",
      "TIMING: dataset construction took 0.801 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.231 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.228 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8600608880939764]\n",
      "computed_metrics: [0.8152441166139797]\n",
      "computed_metrics: [0.8369128688667714]\n",
      "Evaluating model number  3\n",
      "Train ROC-AUC Score:  0.8600608880939764 Valid ROC-AUC Score:  0.8152441166139797 Test ROC-AUC Score:  0.8369128688667714\n",
      "TIMING: dataset construction took 0.807 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.230 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.225 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8646301799184268]\n",
      "computed_metrics: [0.8449122807017544]\n",
      "computed_metrics: [0.8436781609195403]\n",
      "Evaluating model number  4\n",
      "Train ROC-AUC Score:  0.8646301799184268 Valid ROC-AUC Score:  0.8449122807017544 Test ROC-AUC Score:  0.8436781609195403\n",
      "TIMING: dataset construction took 0.618 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.420 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.231 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8761185282204806]\n",
      "computed_metrics: [0.8758377425044093]\n",
      "computed_metrics: [0.8368744512730465]\n",
      "Evaluating model number  5\n",
      "Train ROC-AUC Score:  0.8761185282204806 Valid ROC-AUC Score:  0.8758377425044093 Test ROC-AUC Score:  0.8368744512730465\n",
      "TIMING: dataset construction took 0.623 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.439 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.235 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8775503748022832]\n",
      "computed_metrics: [0.8336868151290209]\n",
      "computed_metrics: [0.9032484635645303]\n",
      "Evaluating model number  6\n",
      "Train ROC-AUC Score:  0.8775503748022832 Valid ROC-AUC Score:  0.8336868151290209 Test ROC-AUC Score:  0.9032484635645303\n",
      "TIMING: dataset construction took 0.608 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.230 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.419 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8992932277769201]\n",
      "computed_metrics: [0.8544081489286969]\n",
      "computed_metrics: [0.8433797909407665]\n",
      "Evaluating model number  7\n",
      "Train ROC-AUC Score:  0.8992932277769201 Valid ROC-AUC Score:  0.8544081489286969 Test ROC-AUC Score:  0.8433797909407665\n",
      "TIMING: dataset construction took 0.937 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.279 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.277 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.8973191142709028]\n",
      "computed_metrics: [0.8560606060606061]\n",
      "computed_metrics: [0.828503301540719]\n",
      "Evaluating model number  8\n",
      "Train ROC-AUC Score:  0.8973191142709028 Valid ROC-AUC Score:  0.8560606060606061 Test ROC-AUC Score:  0.828503301540719\n",
      "TIMING: dataset construction took 0.942 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.273 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.273 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.906699887734437]\n",
      "computed_metrics: [0.8959507042253521]\n",
      "computed_metrics: [0.8481324876673714]\n",
      "Evaluating model number  9\n",
      "Train ROC-AUC Score:  0.906699887734437 Valid ROC-AUC Score:  0.8959507042253521 Test ROC-AUC Score:  0.8481324876673714\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\") # define metric as roc_auc_score\n",
    "\n",
    "num_models = 10 # the number of iteration\n",
    "rocauc_train = [] # save rocauc value for training dataset\n",
    "rocauc_valid = [] # save rocauc value for validation dataset\n",
    "rocauc_test = [] # save rocauc value for test dataset\n",
    "\n",
    "# Do featurization\n",
    "conv_feature = make_feature('BACE','GraphConv')\n",
    "\n",
    "for i in range(num_models):\n",
    "    # Load ith dataset with GraphConv Featurizer and random split\n",
    "    train_dataset, valid_dataset, test_dataset = split_data(conv_feature)\n",
    "    \n",
    "    # Fitting ith model with training dataset\n",
    "    gcn_model.fit(train_dataset, 3) # fitting with training epoch 3\n",
    "    \n",
    "    # Evaluating model   \n",
    "    # save rocauc for training dataset\n",
    "    pred_train = gcn_model.predict(train_dataset)\n",
    "    pred_train = process_prediction(train_dataset.y, pred_train)\n",
    "    train_scores = metric.compute_metric(train_dataset.y, pred_train, train_dataset.w)\n",
    "    rocauc_train.append(train_scores)\n",
    "\n",
    "    # save rocauc for valid dataset\n",
    "    pred_valid = gcn_model.predict(valid_dataset)\n",
    "    pred_valid = process_prediction(valid_dataset.y, pred_valid)\n",
    "    valid_scores = metric.compute_metric(valid_dataset.y, pred_valid, valid_dataset.w)\n",
    "    rocauc_valid.append(valid_scores)\n",
    "   \n",
    "    # save rocauc for test dataset\n",
    "    pred_test = gcn_model.predict(test_dataset)\n",
    "    pred_test = process_prediction(test_dataset.y, pred_test)\n",
    "    test_scores = metric.compute_metric(test_dataset.y, pred_test, test_dataset.w)\n",
    "    rocauc_test.append(test_scores)   \n",
    "    \n",
    "    # print rocauc result\n",
    "    print(\"Evaluating model number \", i)\n",
    "    print(\"Train ROC-AUC Score: \" , train_scores,  \n",
    "          \"Valid ROC-AUC Score: \" , valid_scores,\n",
    "          \"Test ROC-AUC Score: \" , test_scores)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean value of ROC-AUC and use std1 for error bar in GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_values = []\n",
    "gcn_values.append(np.mean(rocauc_train))\n",
    "gcn_values.append(np.mean(rocauc_valid))\n",
    "gcn_values.append(np.mean(rocauc_test))\n",
    "gcn_stds = []\n",
    "gcn_stds.append(np.std(rocauc_train))\n",
    "gcn_stds.append(np.std(rocauc_valid))\n",
    "gcn_stds.append(np.std(rocauc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Multi Layer Perceptron using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MLP\n",
    "batch_size = 50\n",
    "dense_model = MLP(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Multi Layer Percpetron Model and Calculate ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ../data/bace.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 3.317 s\n",
      "TIMING: dataset construction took 3.482 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.069 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.064 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.030 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.030 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.9215662514561742]\n",
      "computed_metrics: [0.8438380281690141]\n",
      "computed_metrics: [0.8372620918456435]\n",
      "Evaluating model number  0\n",
      "Train ROC-AUC Score:  0.9215662514561742 Valid ROC-AUC Score:  0.8438380281690141 Test ROC-AUC Score:  0.8372620918456435\n",
      "TIMING: dataset construction took 0.067 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.028 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.028 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.9550267168018998]\n",
      "computed_metrics: [0.9353233830845771]\n",
      "computed_metrics: [0.8760570824524312]\n",
      "Evaluating model number  1\n",
      "Train ROC-AUC Score:  0.9550267168018998 Valid ROC-AUC Score:  0.9353233830845771 Test ROC-AUC Score:  0.8760570824524312\n",
      "TIMING: dataset construction took 0.054 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.024 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.024 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.9822450657894737]\n",
      "computed_metrics: [0.8928053642624139]\n",
      "computed_metrics: [0.9422270821942773]\n",
      "Evaluating model number  2\n",
      "Train ROC-AUC Score:  0.9822450657894737 Valid ROC-AUC Score:  0.8928053642624139 Test ROC-AUC Score:  0.9422270821942773\n",
      "TIMING: dataset construction took 0.054 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.024 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.024 s\n",
      "Loading dataset from disk.\n",
      "computed_metrics: [0.99203738317757]\n",
      "computed_metrics: [0.9737213403880072]\n",
      "computed_metrics: [0.9579220779220778]\n",
      "Evaluating model number  3\n",
      "Train ROC-AUC Score:  0.99203738317757 Valid ROC-AUC Score:  0.9737213403880072 Test ROC-AUC Score:  0.9579220779220778\n",
      "TIMING: dataset construction took 0.067 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.028 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.028 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\") # define metric as roc_auc_score\n",
    "\n",
    "num_models = 10 # the number of iteration\n",
    "rocauc_train = [] # save rocauc value for training dataset\n",
    "rocauc_valid = [] # save rocauc value for validation dataset\n",
    "rocauc_test = [] # save rocauc value for test dataset\n",
    "\n",
    "# Do featurization\n",
    "ecfp_feature = make_feature('BACE','ECFP')\n",
    "\n",
    "for i in range(num_models):\n",
    "    # Load ith dataset with GraphConv Featurizer and random split\n",
    "    train_dataset, valid_dataset, test_dataset = split_data(ecfp_feature)\n",
    "    \n",
    "    # Fitting ith model with training dataset\n",
    "    dense_model.fit(train_dataset, 3) # fitting with training epoch 3\n",
    "    \n",
    "    # Evaluating model   \n",
    "    # save rocauc for training dataset\n",
    "    pred_train = dense_model.predict(train_dataset)\n",
    "    pred_train = process_prediction(train_dataset.y, pred_train)\n",
    "    train_scores = metric.compute_metric(train_dataset.y, pred_train)\n",
    "    rocauc_train.append(train_scores)\n",
    "\n",
    "    # save rocauc for valid dataset\n",
    "    pred_valid = dense_model.predict(valid_dataset)\n",
    "    pred_valid = process_prediction(valid_dataset.y, pred_valid)\n",
    "    valid_scores = metric.compute_metric(valid_dataset.y, pred_valid)\n",
    "    rocauc_valid.append(valid_scores)\n",
    "   \n",
    "    # save rocauc for test dataset\n",
    "    pred_test = dense_model.predict(test_dataset)\n",
    "    pred_test = process_prediction(test_dataset.y, pred_test)\n",
    "    test_scores = metric.compute_metric(test_dataset.y, pred_test)\n",
    "    rocauc_test.append(test_scores)   \n",
    "    \n",
    "    # print rocauc result\n",
    "    print(\"Evaluating model number \", i)\n",
    "    print(\"Train ROC-AUC Score: \" , train_scores,  \n",
    "          \"Valid ROC-AUC Score: \" , valid_scores,\n",
    "          \"Test ROC-AUC Score: \" , test_scores)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean value of ROC-AUC and use std1 for error bar in MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_values = []\n",
    "mlp_values.append(np.mean(rocauc_train))\n",
    "mlp_values.append(np.mean(rocauc_valid))\n",
    "mlp_values.append(np.mean(rocauc_test))\n",
    "mlp_stds = []\n",
    "mlp_stds.append(np.std(rocauc_train))\n",
    "mlp_stds.append(np.std(rocauc_valid))\n",
    "mlp_stds.append(np.std(rocauc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "topics = ['train', 'valid', 'test']\n",
    "\n",
    "def create_x(t, w, n, d):\n",
    "    return [t*x + w*n for x in range(d)]\n",
    "\n",
    "gcn_values_x = create_x(2, 0.8, 1, 3)\n",
    "mlp_values_x = create_x(2, 0.8, 2, 3)\n",
    "\n",
    "ax = plt.subplot()\n",
    "p1 = ax.bar(gcn_values_x, gcn_values, yerr=gcn_stds, capsize=1)\n",
    "p2 = ax.bar(mlp_values_x, mlp_values, yerr=mlp_stds, capsize=1)\n",
    "\n",
    "middle_x = [(a+b)/2 for (a,b) in zip(gcn_values_x, mlp_values_x)]\n",
    "\n",
    "ax.set_title('Mean ROC-AUC Score for GCN/MLP Model')\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('ROC-AUC Score')\n",
    "ax.legend((p1[0], p2[0]), ('GCN', 'MLP'), fontsize=15)\n",
    "ax.set_xticks(middle_x)\n",
    "ax.set_xticklabels(topics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dckernel",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
